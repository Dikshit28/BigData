{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "# from pyspark import SparkContext\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['PYSPARK_PYTHON'] = sys.executable\n",
    "os.environ['PYSPARK_DRIVER_PYTHON'] = sys.executable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sc = SparkContext(\"local\", \"app_1\")\n",
    "spark = SparkSession.builder.master(\"local\").appName(\"app_1\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [('John', 45, 'IT'), ('Sam', 40, 'HR'), ('Smith', 41, 'IT')]\n",
    "rdd = spark.sparkContext.parallelize(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame[_1: string, _2: bigint, _3: string]\n"
     ]
    }
   ],
   "source": [
    "df = rdd.toDF()\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _1: string (nullable = true)\n",
      " |-- _2: long (nullable = true)\n",
      " |-- _3: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame[id: string, name: bigint, dept: string]\n"
     ]
    }
   ],
   "source": [
    "columns=['id','name','dept']\n",
    "df2= rdd.toDF(columns)\n",
    "print(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----+----+\n",
      "|   id|name|dept|\n",
      "+-----+----+----+\n",
      "| John|  45|  IT|\n",
      "|  Sam|  40|  HR|\n",
      "|Smith|  41|  IT|\n",
      "+-----+----+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "anime=spark.read.csv('anime.csv',header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+--------------------+-----+--------+------+-------+\n",
      "|anime_id|                name|               genre| type|episodes|rating|members|\n",
      "+--------+--------------------+--------------------+-----+--------+------+-------+\n",
      "|   32281|      Kimi no Na wa.|Drama, Romance, S...|Movie|       1|  9.37| 200630|\n",
      "|    5114|Fullmetal Alchemi...|Action, Adventure...|   TV|      64|  9.26| 793665|\n",
      "|   28977|            GintamaÂ°|Action, Comedy, H...|   TV|      51|  9.25| 114262|\n",
      "|    9253|         Steins;Gate|    Sci-Fi, Thriller|   TV|      24|  9.17| 673572|\n",
      "|    9969|       Gintama&#039;|Action, Comedy, H...|   TV|      51|  9.16| 151266|\n",
      "|   32935|Haikyuu!!: Karasu...|Comedy, Drama, Sc...|   TV|      10|  9.15|  93351|\n",
      "|   11061|Hunter x Hunter (...|Action, Adventure...|   TV|     148|  9.13| 425855|\n",
      "|     820|Ginga Eiyuu Densetsu|Drama, Military, ...|  OVA|     110|  9.11|  80679|\n",
      "|   15335|Gintama Movie: Ka...|Action, Comedy, H...|Movie|       1|  9.10|  72534|\n",
      "|   15417|Gintama&#039;: En...|Action, Comedy, H...|   TV|      13|  9.11|  81109|\n",
      "|    4181|Clannad: After Story|Drama, Fantasy, R...|   TV|      24|  9.06| 456749|\n",
      "|   28851|      Koe no Katachi|Drama, School, Sh...|Movie|       1|  9.05| 102733|\n",
      "|     918|             Gintama|Action, Comedy, H...|   TV|     201|  9.04| 336376|\n",
      "|    2904|Code Geass: Hangy...|Action, Drama, Me...|   TV|      25|  8.98| 572888|\n",
      "|   28891|Haikyuu!! Second ...|Comedy, Drama, Sc...|   TV|      25|  8.93| 179342|\n",
      "|     199|Sen to Chihiro no...|Adventure, Drama,...|Movie|       1|  8.93| 466254|\n",
      "|   23273|Shigatsu wa Kimi ...|Drama, Music, Rom...|   TV|      22|  8.92| 416397|\n",
      "|   24701|Mushishi Zoku Sho...|Adventure, Fantas...|   TV|      10|  8.88|  75894|\n",
      "|   12355|Ookami Kodomo no ...|Fantasy, Slice of...|Movie|       1|  8.84| 226193|\n",
      "|    1575|Code Geass: Hangy...|Action, Mecha, Mi...|   TV|      25|  8.83| 715151|\n",
      "+--------+--------------------+--------------------+-----+--------+------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "anime.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.sparkContext.parallelize([(1, 2, 3, 'a b c'),\n",
    "(4, 5, 6, 'd e f'),\n",
    "(7, 8, 9, 'g h i')]).toDF(['col1', 'col2', 'col3','col4'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----+----+-----+\n",
      "|col1|col2|col3| col4|\n",
      "+----+----+----+-----+\n",
      "|   1|   2|   3|a b c|\n",
      "|   4|   5|   6|d e f|\n",
      "|   7|   8|   9|g h i|\n",
      "+----+----+----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "myData = spark.sparkContext.parallelize([(1,2), (3,4), (5,6), (7,8), (9,10)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 2), (3, 4), (5, 6), (7, 8), (9, 10)]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myData.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "Employee = spark.createDataFrame([\n",
    "    ('1', 'Joe', '70000', '1'),\n",
    "    ('2', 'Henry', '80000', '2'),\n",
    "    ('3', 'Sam', '60000', '2'),\n",
    "    ('4', 'Max', '90000', '1')],\n",
    "    ['Id', 'Name', 'Sallary', 'DepartmentId']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+-------+------------+\n",
      "| Id| Name|Sallary|DepartmentId|\n",
      "+---+-----+-------+------------+\n",
      "|  1|  Joe|  70000|           1|\n",
      "|  2|Henry|  80000|           2|\n",
      "|  3|  Sam|  60000|           2|\n",
      "|  4|  Max|  90000|           1|\n",
      "+---+-----+-------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Employee.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SPARK DF vs Pandas DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_list = [['a', 1, 2], ['b', 2, 3], ['c', 3, 4]]\n",
    "col_name = ['A', 'B', 'C']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>b</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>c</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   A  B  C\n",
       "0  a  1  2\n",
       "1  b  2  3\n",
       "2  c  3  4"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# caution for the columns=\n",
    "pd.DataFrame(my_list, columns=col_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+---+\n",
      "|  A|  B|  C|\n",
      "+---+---+---+\n",
      "|  a|  1|  2|\n",
      "|  b|  2|  3|\n",
      "|  c|  3|  4|\n",
      "+---+---+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.createDataFrame(my_list, col_name).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {'A': [0, 1, 0],\n",
    "     'B': [1, 0, 1],\n",
    "     'C': [1, 0, 0]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   A  B  C\n",
       "0  0  1  1\n",
       "1  1  0  0\n",
       "2  0  1  0"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+---+\n",
      "|  A|  B|  C|\n",
      "+---+---+---+\n",
      "|  0|  1|  1|\n",
      "|  1|  0|  0|\n",
      "|  0|  1|  0|\n",
      "+---+---+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.createDataFrame(np.array(list(d.values())).T.tolist(), list(d.keys())).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "fac48fc003d09745832f48699b6e0a240bc4e57c224824a17253c3f022e22a71"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
